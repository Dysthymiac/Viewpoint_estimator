{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff263d34",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c85fb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Enable interactive matplotlib for 3D visualization\n",
    "# %matplotlib widget\n",
    "\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(str(Path(\"..\")))\n",
    "\n",
    "# Import required modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "# Import project modules\n",
    "from src.utils.config import load_config\n",
    "from src.data.cvat_loader import CVATLoader\n",
    "from src.data.coco_loader import COCOLoader\n",
    "\n",
    "# Set up matplotlib\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"All modules imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d9939d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "# config = load_config(Path(\"../config.yaml\"))\n",
    "config_path = Path(\"./config_zebra_test.yaml\")\n",
    "config = load_config(config_path)\n",
    "print(f\"Configuration loaded from config.yaml\")\n",
    "print(f\"Dataset: {config['dataset']['root_path']}\")\n",
    "print(f\"Analysis method: {config['analysis']['method']}\")\n",
    "\n",
    "dataset_config = config['dataset']\n",
    "dataset_root = \"..\"/Path(dataset_config['root_path'])\n",
    "crop_to_bbox = dataset_config.get('crop_to_bbox', True)\n",
    "dataset_format = dataset_config.get('format', 'cvat')  # Default to CVAT for backward compatibility\n",
    "\n",
    "# Use images_dir to override root_path if provided\n",
    "if 'images_dir' in dataset_config and dataset_config['images_dir']:\n",
    "    image_root = Path(dataset_config['images_dir'])\n",
    "    if not image_root.is_absolute():\n",
    "        image_root = dataset_root / dataset_config['images_dir']\n",
    "else:\n",
    "    image_root = dataset_root\n",
    "\n",
    "if dataset_format.lower() == 'coco':\n",
    "    annotations_file = dataset_config['annotations_file']\n",
    "    coco_json_path = dataset_root / annotations_file\n",
    "    loader = COCOLoader(coco_json_path, image_root, crop_to_bbox=crop_to_bbox)\n",
    "    print(f\"Loaded COCO dataset: {len(loader)} annotations\")\n",
    "    print(f\"Annotations from: {coco_json_path}\")\n",
    "    print(f\"Images from: {image_root}\")\n",
    "elif dataset_format.lower() == 'cvat':\n",
    "    loader = CVATLoader(dataset_root, crop_to_bbox=crop_to_bbox)\n",
    "    print(f\"Loaded CVAT dataset: {len(loader)} annotations\")\n",
    "    print(f\"Dataset root: {dataset_root}\")\n",
    "annotations = loader.annotations.copy()\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Total images: {len(annotations)}\")\n",
    "print(f\"  Crop to bbox: {crop_to_bbox}\")\n",
    "\n",
    "# Show viewpoint distribution\n",
    "viewpoints = [ann.viewpoint for ann in annotations]\n",
    "unique_viewpoints, counts = np.unique(viewpoints, return_counts=True)\n",
    "print(f\"\\nViewpoint distribution:\")\n",
    "for vp, count in zip(unique_viewpoints, counts):\n",
    "    print(f\"  {vp}: {count} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e0ba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.animal_detection_pipeline import create_pipeline_from_main_config\n",
    "\n",
    "\n",
    "pipeline = create_pipeline_from_main_config(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b028b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.detection.animal_detector import detect_animals_with_depth, detect_animals_with_sam2, get_body_part_bounding_box, get_detection_body_part_boxes, hierarchical_animal_detection\n",
    "from src.classification.viewpoint_3d import estimate_viewpoint_for_detections\n",
    "from src.visualization.detection_visualization import visualize_detection_viewpoints, visualize_sam2_detections\n",
    "from PIL import Image\n",
    "\n",
    "annotations_filtered = [ann for ann in annotations if ann.category=='zebra_plains']\n",
    "\n",
    "annotation = annotations_filtered[15]\n",
    "# annotation = annotations[897]\n",
    "# annotation = [a for a in annotations if \"CT185-465_IMG_0835.JPG\" in str(a.image_path)]\n",
    "# image = Image.open(\"../../CT185-465_IMG_0835.JPG\")\n",
    "image = loader.load_image(annotation)\n",
    "# image = detection_results[1]['image']\n",
    "image = Image.open(\"/fs/ess/PAS2136/ggr_data/kate/beluga/images/test2022/images/test0001.jpg\")\n",
    "\n",
    "detections, info = pipeline.process(image)\n",
    "\n",
    "fig1 = visualize_sam2_detections(\n",
    "      image=image,\n",
    "      detections=detections,\n",
    "      patch_coordinates=info[\"patch_coordinates\"],\n",
    "      relative_patch_size=info[\"relative_patch_size\"],\n",
    "      show_patches=True\n",
    "  )\n",
    "plt.show()\n",
    "\n",
    "fig2 = visualize_detection_viewpoints(\n",
    "    image=image,\n",
    "    detections_with_viewpoints=detections,\n",
    "    patch_components=info[\"patch_components\"],\n",
    "    patch_coordinates=info[\"patch_coordinates\"],\n",
    "    cluster_labels=info[\"cluster_labels\"],\n",
    "    relative_patch_size=info[\"relative_patch_size\"],\n",
    "    image_resize=1024,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b85172bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf98fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for annotation in annotations:\n",
    "    image = loader.load_image(annotation)\n",
    "    detections, info = pipeline.process(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad399df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
